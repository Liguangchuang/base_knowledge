{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0d4cb14f7d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mX_test_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_X_train_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_SENT_NUM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_SENT_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0my_train_oneHot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_y_train_oneHot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0my_test_oneHot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_y_train_oneHot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workCode\\机器学习\\deep_model\\tf\\HAN\\data_utils.py\u001b[0m in \u001b[0;36mmake_y_train_oneHot\u001b[1;34m(y_train_idx)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0my_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_set\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mcate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import imdb\n",
    "from data_utils import train_W2V, load_W2V, build_word2idx_embedMatrix, make_X_train_idx\n",
    "from data_utils import make_y_train_oneHot, evaluate_matrix, load_data, W2V_corpus_iter\n",
    "from data_utils import split_words\n",
    "from HAN_model import HAN_train_test\n",
    "\n",
    "MAX_SENT_NUM = 20\n",
    "MAX_SENT_LEN = 250\n",
    "in_path = '../../../../deep_data/'\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train = load_data(in_path + 'yelp-2014-seg-20-20.train.ss')\n",
    "    X_test, y_test = load_data(in_path + 'yelp-2014-seg-20-20.test.ss')\n",
    "\n",
    "    X_train = [paragraph.split(' <sssss> ') for paragraph in X_train] [0: ]\n",
    "    X_test = [paragraph.split(' <sssss> ') for paragraph in X_test] [0: ]\n",
    "\n",
    "    X_train = [[split_words(sent) for sent in paragraph] for paragraph in X_train]\n",
    "    X_test = [[split_words(sent) for sent in paragraph] for paragraph in X_test]\n",
    "\n",
    "    W2V_corpus = W2V_corpus_iter(X_train)\n",
    "    w2vModel = train_W2V(W2V_corpus, in_path + 'w2vModel')\n",
    "    word2idx, embedMatrix = build_word2idx_embedMatrix(w2vModel)  # 制作word2idx和embedMatrix\n",
    "\n",
    "    X_train_idx = make_X_train_idx(X_train, word2idx, MAX_SENT_NUM, MAX_SENT_LEN)\n",
    "    X_test_idx = make_X_train_idx(X_test, word2idx, MAX_SENT_NUM, MAX_SENT_LEN)\n",
    "\n",
    "    y_train_oneHot = make_y_train_oneHot(y_train)\n",
    "    y_test_oneHot = make_y_train_oneHot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————模型的训练和预测——————————————\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sequence_length must be a vector of length batch_size, but saw shape: ()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c2cb247051a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'——————————————模型的训练和预测——————————————'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHAN_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_oneHot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_oneHot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# y_pred = model.test([X_val_idx, y_val_oneHot])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workCode\\机器学习\\deep_model\\tf\\HAN\\HAN_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, embedd_matrix)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0matten_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(bs, hs*2)  inputs->(bs, seq_len, hs*2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0matten_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workCode\\机器学习\\deep_model\\tf\\HAN\\HAN_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, embedd_matrix)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# 建立模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbulit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workCode\\机器学习\\deep_model\\tf\\HAN\\HAN_model.py\u001b[0m in \u001b[0;36mbulit_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# (bs*max_sent_num, max_sent_len, hs*2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embedd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Bi_GRU_Encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embedd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word_encoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# (bs*max_sent_num, hs*2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workCode\\机器学习\\deep_model\\tf\\HAN\\HAN_model.py\u001b[0m in \u001b[0;36m_Bi_GRU_Encoder\u001b[1;34m(self, inputs, name)\u001b[0m\n\u001b[0;32m     87\u001b[0m                                                                                  \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                                                                                  \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                                                                                  dtype=tf.float32)\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mbiGRU_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfw_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#(bs, seq_len, hidden*2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbiGRU_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\mySoftware\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mbidirectional_dynamic_rnn\u001b[1;34m(cell_fw, cell_bw, inputs, sequence_length, initial_state_fw, initial_state_bw, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    437\u001b[0m           \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_state_fw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m           time_major=time_major, scope=fw_scope)\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;31m# Backward direction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\mySoftware\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    621\u001b[0m         raise ValueError(\n\u001b[0;32m    622\u001b[0m             \u001b[1;34m\"sequence_length must be a vector of length batch_size, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \"but saw shape: %s\" % sequence_length.get_shape())\n\u001b[0m\u001b[0;32m    624\u001b[0m       sequence_length = array_ops.identity(  # Just to find it in the graph.\n\u001b[0;32m    625\u001b[0m           sequence_length, name=\"sequence_length\")\n",
      "\u001b[1;31mValueError\u001b[0m: sequence_length must be a vector of length batch_size, but saw shape: ()"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "    print('——————————————模型的训练和预测——————————————')\n",
    "    model = HAN_train_test(embedMatrix)\n",
    "\n",
    "    model.train([X_train_idx, y_train_oneHot, X_test_idx, y_test_oneHot])\n",
    "    # y_pred = model.test([X_val_idx, y_val_oneHot])\n",
    "    # print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "(3, 4)\n",
      "(2, 4)\n",
      "(3, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([[[1, 2, 3],[4, 5, 6]], [[1, 2, 3],[4, 5, 6]], [[1, 2, 3],[4, 5, 6]]])  \n",
    "w=np.array([[ 7,  8, 4, 4],[ 9, 10, 4, 4],[11, 12, 4, 4]])  \n",
    "b=np.array([[3,3, 4, 4],[3,3, 4, 4]])\n",
    "\n",
    "print(x.shape)\n",
    "print(w.shape)\n",
    "print(b.shape)\n",
    "\n",
    "result2 = np.matmul(x, w) + b\n",
    "\n",
    "print(result2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 61,  67],\n",
       "        [142, 157]],\n",
       "\n",
       "       [[ 61,  67],\n",
       "        [142, 157]],\n",
       "\n",
       "       [[ 61,  67],\n",
       "        [142, 157]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 58,  64],\n",
       "        [139, 154]],\n",
       "\n",
       "       [[ 58,  64],\n",
       "        [139, 154]],\n",
       "\n",
       "       [[ 58,  64],\n",
       "        [139, 154]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=[[[1, 2, 3],[4, 5, 6]], [[1, 2, 3],[4, 5, 6]], [[1, 2, 3],[4, 5, 6]]]  \n",
    "w=[[ 7,  8],[ 9, 10],[11, 12]]  \n",
    "b=[[3,3],[3,3]]\n",
    "\n",
    "result2 = np.matmul(x, w)\n",
    "\n",
    "result2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
